{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j3H-w1VAeaXp",
    "ExecuteTime": {
     "end_time": "2024-04-12T13:58:21.407873Z",
     "start_time": "2024-04-12T13:57:17.955018Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_set = datasets.FashionMNIST('Data_FashionMNIST/', download=True, train=True, transform=transform)\n",
    "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = datasets.FashionMNIST('DATA_FashionMNIST/', download=True, train=False, transform=transform)\n",
    "testLoader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZhPxvLReej_",
    "outputId": "e6e2ff39-d9b8-43a0-bd0e-e5d75840665b",
    "ExecuteTime": {
     "end_time": "2024-04-12T14:00:48.264389Z",
     "start_time": "2024-04-12T14:00:48.036769Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "training_data = enumerate(trainLoader)\n",
    "batch_idx, (images, labels) = next(training_data)\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "def show_images (images , labels):\n",
    "    fig = plt.figure()\n",
    "    for i in range(4):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.imshow(images[i][0], cmap='gray')\n",
    "        #print(images[i][0].shape)\n",
    "        plt.title(\"Original Truth Label: {}\".format(labels[i]))\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "    plt.show()\n",
    "\n",
    "def show_image (image , label):\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    #print(images[i][0].shape)\n",
    "    #plt.title(\"Original Truth Label: {}\".format(label[i]))\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.show()\n",
    "\n",
    "#show_image(images[0] , labels[0])\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xgBX-WFel9j",
    "outputId": "8fa5a67a-2b4c-46c5-fdb1-01afcf3b6aa2",
    "ExecuteTime": {
     "end_time": "2024-04-12T14:00:52.114249Z",
     "start_time": "2024-04-12T14:00:51.922041Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def get_noise(n_samples, noise_vector_dimension, device='cpu'):\n",
    "    return torch.randn(n_samples, noise_vector_dimension, device=device)"
   ],
   "metadata": {
    "id": "SSfMMb4Oeqgm",
    "ExecuteTime": {
     "end_time": "2024-04-12T14:00:56.059440Z",
     "start_time": "2024-04-12T14:00:56.053Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dimension=100, hidden_dimension=128):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.n_dim = noise_dimension\n",
    "        self.h_dim = hidden_dimension\n",
    "\n",
    "        self.init_size = 7  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(self.n_dim, self.init_size * self.init_size * self.h_dim))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(self.h_dim),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(self.h_dim, self.h_dim // 2, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(self.h_dim // 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(self.h_dim // 2, 1, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        out = self.l1(noise)\n",
    "        out = out.view(out.shape[0], self.h_dim, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "##%%\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.disc = nn.Sequential(\n",
    "            # Convolutional layer taking in 1 input channel (image), outputting 64 channels\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2),  # 'same' padding in PyTorch is achieved with padding=2 for a 5x5 kernel\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            # Second convolutional layer, 64 input channels, 128 output channels\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(0.3, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            # Flatten the output for the dense layer\n",
    "            nn.Flatten(),\n",
    "\n",
    "            # Final dense layer to get to 1 output\n",
    "            nn.Linear(128 * 7 * 7, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ],
   "metadata": {
    "id": "I10mOxVhesLA",
    "ExecuteTime": {
     "end_time": "2024-04-12T14:00:56.988104Z",
     "start_time": "2024-04-12T14:00:56.967163Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n"
   ],
   "metadata": {
    "id": "bwdE1c52e88A",
    "ExecuteTime": {
     "end_time": "2024-04-12T14:00:57.906193Z",
     "start_time": "2024-04-12T14:00:57.866463Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Training settings\n",
    "num_epochs = 50  # Number of epochs to train for\n",
    "batch_size = 64  # Batch size\n",
    "noise_dimension = 100  # Dimension of the noise vector\n",
    "data_loader = trainLoader\n",
    "# Define optimizers for both generator and discriminator\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "optimizer_generator = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "# Binary cross-entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "# Placeholder for logging\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.to(device)  # Move images to the same device as the model\n",
    "        real_labels = torch.ones(images.size(0), 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train discriminator with real images\n",
    "        discriminator.zero_grad()\n",
    "        real_loss = criterion(discriminator(images), real_labels)\n",
    "        real_loss.backward()\n",
    "\n",
    "        # Generate fake images\n",
    "        noise = torch.randn(batch_size, noise_dimension, device=device)\n",
    "        fake_images = generator(noise)\n",
    "\n",
    "        # Train discriminator with fake images\n",
    "        fake_loss = criterion(discriminator(fake_images.detach()), fake_labels)\n",
    "        fake_loss.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        # Train generator\n",
    "        generator.zero_grad()\n",
    "        fake_labels.fill_(1.0)  # fake labels are real for generator cost\n",
    "        gen_loss = criterion(discriminator(fake_images), fake_labels)\n",
    "        gen_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(data_loader)}], D_loss: {real_loss.item() + fake_loss.item()}, G_loss: {gen_loss.item()}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "KUsMhaW8e-yL",
    "outputId": "66f36834-5092-4b6b-d1f6-9b5e0ed53f2d",
    "ExecuteTime": {
     "end_time": "2024-04-12T14:11:18.303818Z",
     "start_time": "2024-04-12T14:00:58.514823Z"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/938], D_loss: 1.1754422187805176, G_loss: 0.9435363411903381\n",
      "Epoch [1/50], Step [200/938], D_loss: 1.2443909049034119, G_loss: 1.061617374420166\n",
      "Epoch [1/50], Step [300/938], D_loss: 1.2302883863449097, G_loss: 1.1429463624954224\n",
      "Epoch [1/50], Step [400/938], D_loss: 0.8537188768386841, G_loss: 1.6047155857086182\n",
      "Epoch [1/50], Step [500/938], D_loss: 0.7687949240207672, G_loss: 1.4472119808197021\n",
      "Epoch [1/50], Step [600/938], D_loss: 0.861720085144043, G_loss: 1.2842001914978027\n",
      "Epoch [1/50], Step [700/938], D_loss: 1.238117277622223, G_loss: 1.2057398557662964\n",
      "Epoch [1/50], Step [800/938], D_loss: 1.046956181526184, G_loss: 1.257646083831787\n",
      "Epoch [1/50], Step [900/938], D_loss: 1.128619134426117, G_loss: 1.473925232887268\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 1, 28, 28]' is invalid for input of size 50176",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 28\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# Train discriminator with fake images\u001B[39;00m\n\u001B[0;32m     27\u001B[0m noise \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(batch_size, noise_dimension , device \u001B[38;5;241m=\u001B[39m device)\n\u001B[1;32m---> 28\u001B[0m fake_images \u001B[38;5;241m=\u001B[39m generator(noise)\u001B[38;5;241m.\u001B[39mreshape (images\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m28\u001B[39m)\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m#Train discriminator with fake images\u001B[39;00m\n\u001B[0;32m     31\u001B[0m fake_labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(fake_images\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m1\u001B[39m, device \u001B[38;5;241m=\u001B[39m device)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[32, 1, 28, 28]' is invalid for input of size 50176"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_fake_images(generator, noise_dimension, device):\n",
    "    noise = torch.randn(16, noise_dimension, device=device)\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(noise).reshape(-1, 1, 28, 28)\n",
    "        fake_images = fake_images.cpu().detach().numpy()\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        img = fake_images[i].transpose(1, 2, 0)\n",
    "        img = ((img - img.min()) * (1 / (img.max() - img.min()) * 255)).astype(np.uint8)\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the fake images\n",
    "plot_fake_images(generator, noise_dimension, device)\n"
   ],
   "metadata": {
    "id": "OB0ArJ7XfBzF"
   },
   "execution_count": 7,
   "outputs": []
  }
 ]
}
