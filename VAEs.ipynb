{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9901e6bfc105bab0",
   "metadata": {},
   "source": [
    "## VAEs- Deep Unsupervised Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T21:17:24.555809900Z",
     "start_time": "2024-04-06T21:17:07.892509Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e0235db2bf6799",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "### Choose device\n",
    "### Define transformations\n",
    "### Load datasets\n",
    "### Inspect a batch (for understanding)\n",
    "### Visualize sample images (for understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e464a59b6d1c3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T21:17:27.785811300Z",
     "start_time": "2024-04-06T21:17:27.641813500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Choose device\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1,), (0.3,))\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "\n",
    "train_set = datasets.FashionMNIST('Data_FashionMNIST/', download=True, train=True, transform=transform)\n",
    "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = datasets.FashionMNIST('DATA_FashionMNIST/', download=True, train=False, transform=transform)\n",
    "testLoader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257de657d55ab0a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T21:17:30.933810Z",
     "start_time": "2024-04-06T21:17:30.893813200Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_reconstructed_batch(model, data, reconstructed_data):\n",
    "    # Get a grid of images from the batch\n",
    "    images = data.view(-1, 28, 28)\n",
    "    reconstructed_images = reconstructed_data.view(-1, 28, 28)\n",
    "    \n",
    "    # Ajustar el tamaño de la cuadrícula\n",
    "    fig, axs = plt.subplots(2, len(images), figsize=(10, 5))\n",
    "    \n",
    "    # Verificar la lógica de indexación\n",
    "    for i in range(len(reconstructed_images)):\n",
    "        axs[0, i].imshow(images[i].detach().numpy(), cmap=\"gray\")  # Salia un error relacionado a arrays, añadió detach() y numpy()\n",
    "        axs[0, i].set_title(\"Original\")\n",
    "        axs[0, i].axis('off')\n",
    "\n",
    "        axs[1, i].imshow(reconstructed_images[i].detach().numpy(), cmap=\"gray\")  # Se añadió detach() y numpy()\n",
    "        axs[1, i].set_title(\"Reconstructed\")\n",
    "        axs[1, i].axis('off')\n",
    "\n",
    "    fig.suptitle(\"Sample Reconstructed Images\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a93a3165e74d558",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T21:17:33.530812600Z",
     "start_time": "2024-04-06T21:17:33.477812100Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 20),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Reparameterización\n",
    "        self.mu = nn.Linear(20, 10)\n",
    "        self.logvar = nn.Linear(20, 10)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400, 784),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu = self.mu(h)\n",
    "        logvar = self.logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.decoder(z)\n",
    "        return h\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstructed_x = self.decode(z)\n",
    "        return reconstructed_x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a57dc0b53fe55c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T21:17:43.235812600Z",
     "start_time": "2024-04-06T21:17:43.161810700Z"
    }
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_hidden=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set the number of hidden units\n",
    "        self.num_hidden = num_hidden\n",
    "\n",
    "        # Define the encoder part of the autoencoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 256),  # input size: 784, output size: 256\n",
    "            nn.ReLU(),  # apply the ReLU activation function\n",
    "            nn.Linear(256, self.num_hidden),  # input size: 256, output size: num_hidden\n",
    "            nn.ReLU(),  # apply the ReLU activation function\n",
    "        )\n",
    "\n",
    "        # Define the decoder part of the autoencoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.num_hidden, 256),  # input size: num_hidden, output size: 256\n",
    "            nn.ReLU(),  # apply the ReLU activation function\n",
    "            nn.Linear(256, 784),  # input size: 256, output size: 784\n",
    "            nn.Sigmoid(),  # apply the sigmoid activation function to compress the output to a range of (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z=None):\n",
    "        # Pass the input through the encoder\n",
    "        encoded = self.encoder(x)\n",
    "        # Pass the encoded representation through the decoder\n",
    "        \n",
    "        #Decode input data (reconstruction)\n",
    "        decoded = self.decoder(encoded)\n",
    "        # Return both the encoded representation and the reconstructed output\n",
    "        \n",
    "        # Decode noise vector (image generation)\n",
    "        if z is not None:\n",
    "            generated_image = self.decoder(z)\n",
    "            return encoded, decoded, generated_image\n",
    "        else:\n",
    "            return encoded, decoded, None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4465ed35cb5e6ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T21:17:46.556811900Z",
     "start_time": "2024-04-06T21:17:46.432810900Z"
    }
   },
   "outputs": [],
   "source": [
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a03efb73d510737",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T21:17:49.051814Z",
     "start_time": "2024-04-06T21:17:48.994810500Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(reconstructed_x, x, mu, logvar):\n",
    "    # Reconstrucción\n",
    "    reconstruction_loss = nn.MSELoss()(reconstructed_x, x)\n",
    "\n",
    "    # Regularización KL\n",
    "    kl_divergence = 0.5 * torch.sum(mu**2 + logvar - logvar.exp() - 1, dim=1)\n",
    "    kl_divergence = torch.mean(kl_divergence)\n",
    "\n",
    "    # Pérdida total\n",
    "    loss = reconstruction_loss + kl_divergence\n",
    "    return loss\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecfde0e39b6d52",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-06T21:17:52.860816Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Batch: 0/938, Loss: -8.515525817871094\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, _) in enumerate(trainLoader):\n",
    "        # Aplanar las imágenes\n",
    "        data = data.view(data.size(0), -1)\n",
    "\n",
    "        # Salida del modelo\n",
    "        reconstructed_x, mu, logvar = model(data)\n",
    "\n",
    "        # Cálculo de la pérdida\n",
    "        loss = loss_function(reconstructed_x, data, mu, logvar)\n",
    "\n",
    "        # Optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Impresión de información\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{epochs}, Batch: {batch_idx}/{len(trainLoader)}, Loss: {loss.item()}')\n",
    "\n",
    "            # Visualización de imágenes\n",
    "            clear_output(wait=True)\n",
    "            visualize_reconstructed_batch(model, data, reconstructed_x)\n",
    "\n",
    "# Visualizar una imagen generada aleatoriamente\n",
    "generate_and_visualize_sample(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc5475ff3eac37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
