{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-12T18:48:19.988035160Z",
     "start_time": "2024-04-12T18:48:17.888565116Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_set = datasets.FashionMNIST('Data_FashionMNIST/', download=True, train=True, transform=transform)\n",
    "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "test_set = datasets.FashionMNIST('DATA_FashionMNIST/', download=True, train=False, transform=transform)\n",
    "testLoader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T18:48:20.115426492Z",
     "start_time": "2024-04-12T18:48:19.997208040Z"
    }
   },
   "id": "91936652fec76824",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 4 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "training_data = enumerate(trainLoader)\n",
    "batch_idx, (images, labels) = next(training_data)\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(images[i][0], cmap='gray_r')\n",
    "    plt.title(\"Original Truth Label: {}\".format(labels[i]))\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "plt.show()\n",
    "print(images[0][0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:06:35.817924461Z",
     "start_time": "2024-04-12T20:06:35.738481509Z"
    }
   },
   "id": "de33d4aae7359b08",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=784, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "GaussianMixture(n_components=5)",
      "text/html": "<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianMixture(n_components=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianMixture<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.mixture.GaussianMixture.html\">?<span>Documentation for GaussianMixture</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianMixture(n_components=5)</pre></div> </div></div></div></div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer learning\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "# Move the model to the selected device\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Modify the first convolutional layer to accept single-channel input\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False).to(device)\n",
    "\n",
    "\n",
    "#num_features = model.fc.in_features  # Get the number of input features to the last fully connected layer\n",
    "#model.fc = nn.Linear(num_features, 784).to(device) \n",
    "\n",
    "# Remove the final fully connected layers\n",
    "# model = nn.Sequential(*list(model.children())[:-1])  # Remove the last fully connected layer\n",
    "\n",
    "num_ftrs = model.fc.in_features  # Get the number of input features for the last FC layer\n",
    "model.fc = nn.Linear(num_ftrs, 784).to(device)\n",
    "\n",
    "print(model)\n",
    "# Freeze the parameters so they are not updated during training\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define a function to extract features\n",
    "def extract_features(loader, model):\n",
    "    features = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs.view(outputs.size(0), -1).cpu().numpy())\n",
    "    return np.concatenate(features)\n",
    "\n",
    "# Extract features from the train and test datasets\n",
    "train_features = extract_features(trainLoader, model)\n",
    "test_features = extract_features(testLoader, model)\n",
    "\n",
    "\n",
    "# Now train GaussianMixture model on these extracted features\n",
    "# Reshape the features to have only two dimensions\n",
    "train_features_2d = train_features.reshape(-1, train_features.shape[-1])\n",
    "test_features_2d = test_features.reshape(-1, test_features.shape[-1])\n",
    "\n",
    "# Now train your GMM or any other model on these extracted features\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=5)\n",
    "gmm.fit(train_features_2d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:01:18.029215594Z",
     "start_time": "2024-04-12T19:56:19.073277636Z"
    }
   },
   "id": "fd15e2bc2907b907",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate samples from the GMM\n",
    "generated_samples = torch.tensor(gmm.sample(1)[0])\n",
    "#generated_samples = torch.tensor((1,784))\n",
    "generated_samples = generated_samples.view(28, 28).cpu().detach().numpy()\n",
    "print(generated_samples.shape)\n",
    "\n",
    "# Reshape the generated samples back into image dimensions\n",
    "#generated_image = generated_samples.reshape(22, 22)\n",
    "\n",
    "# Display the generated image\n",
    "plt.imshow(generated_samples, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:07:58.787707729Z",
     "start_time": "2024-04-12T20:07:58.097306394Z"
    }
   },
   "id": "aa63fcbf43b8606a",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (5): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (6): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (7): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T18:57:16.220619780Z",
     "start_time": "2024-04-12T18:57:16.175102176Z"
    }
   },
   "id": "2ba765b034a95a1",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2560 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Step 2: Visualize cluster centers as images\u001B[39;00m\n\u001B[1;32m      8\u001B[0m cluster_centers \u001B[38;5;241m=\u001B[39m gmm\u001B[38;5;241m.\u001B[39mmeans_\n\u001B[0;32m----> 9\u001B[0m cluster_centers_images \u001B[38;5;241m=\u001B[39m \u001B[43mcluster_centers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Reshape to image size\u001B[39;00m\n\u001B[1;32m     11\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m5\u001B[39m))\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(cluster_centers_images\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n",
      "\u001B[0;31mValueError\u001B[0m: cannot reshape array of size 2560 into shape (28,28)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Assign cluster labels to test features\n",
    "test_labels = gmm.predict(test_features_2d)\n",
    "\n",
    "# Step 2: Visualize cluster centers as images\n",
    "cluster_centers = gmm.means_\n",
    "cluster_centers_images = cluster_centers.reshape(-1, 28, 28)  # Reshape to image size\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(cluster_centers_images.shape[0]):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(cluster_centers_images[i], cmap='gray')\n",
    "    plt.title(f'Cluster {i}')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Reconstruct sample images from each cluster\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(cluster_centers.shape[0]):\n",
    "    cluster_samples = test_features_2d[test_labels == i][:5]  # Select 5 samples from each cluster\n",
    "    for j, sample in enumerate(cluster_samples):\n",
    "        reconstructed_image = np.dot(gmm.weights_, gmm.means_).reshape(28, 28)\n",
    "        plt.subplot(5, 5, i * 5 + j + 1)\n",
    "        plt.imshow(reconstructed_image, cmap='gray')\n",
    "        plt.title(f'Cluster {i}')\n",
    "        plt.axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T19:12:09.828334323Z",
     "start_time": "2024-04-12T19:12:09.489193993Z"
    }
   },
   "id": "f662d7169e459626",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(10000,)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T19:12:57.648617650Z",
     "start_time": "2024-04-12T19:12:57.607817229Z"
    }
   },
   "id": "d6c5cd9d97872130",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor\n",
    "sample_input = torch.randn(1, 1, 28, 28).to(device)  # Assuming input size is (batch_size, channels, height, width)\n",
    "\n",
    "# Pass the input through the model\n",
    "output = model(sample_input)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T19:36:16.327069201Z",
     "start_time": "2024-04-12T19:36:16.299249239Z"
    }
   },
   "id": "492eef1e6045dbf1",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed output shape: torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "output = output.view(output.size(0), output.size(1), 1, 1)\n",
    "\n",
    "# Perform upsampling to increase the height and width to 28x28\n",
    "output = F.interpolate(output, size=(28, 28), mode='nearest')\n",
    "\n",
    "# Now, the shape of 'output' is [1, 512, 28, 28], but you want [1, 1, 28, 28]\n",
    "# You can simply take the first channel (since there's only one channel) to get the desired shape\n",
    "output = output[:, :1, :, :]\n",
    "\n",
    "print(\"Transformed output shape:\", output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T19:37:56.056696104Z",
     "start_time": "2024-04-12T19:37:56.013633615Z"
    }
   },
   "id": "cac4e705cb0c0090",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/deep/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/daniel/anaconda3/envs/deep/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 2560 into shape (1,28,28)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 56\u001B[0m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;66;03m# Decode the samples into images (assuming Gaussian distribution of pixel values)\u001B[39;00m\n\u001B[1;32m     55\u001B[0m     samples \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mclip(samples, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 56\u001B[0m     images \u001B[38;5;241m=\u001B[39m \u001B[43msamples\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Reshape into images\u001B[39;00m\n\u001B[1;32m     57\u001B[0m     generated_images\u001B[38;5;241m.\u001B[39mextend(images)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m# Step 6: Plot some of the generated images\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: cannot reshape array of size 2560 into shape (1,28,28)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load the Fashion MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: torch.cat([x, x, x], 0))  # Convert grayscale to RGB\n",
    "])\n",
    "\n",
    "train_set = datasets.FashionMNIST('Data_FashionMNIST/', download=True, train=True, transform=transform)\n",
    "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# Step 2: Preprocess the data (no preprocessing needed for Fashion MNIST)\n",
    "\n",
    "# Step 3: Use a pre-trained ResNet-18 model for feature extraction\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "resnet.fc = torch.nn.Identity()  # Remove the final fully connected layer\n",
    "\n",
    "# Freeze all layers\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet.to(device)\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(data_loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for images, targets in data_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        features.extend(outputs.cpu().detach().numpy())\n",
    "        labels.extend(targets.numpy())\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract features\n",
    "train_features, train_labels = extract_features(trainLoader, resnet)\n",
    "\n",
    "# Step 4: Train a Gaussian Mixture Model (GMM) using the extracted features\n",
    "gmm = GaussianMixture(n_components=10, covariance_type='full')\n",
    "gmm.fit(train_features)\n",
    "\n",
    "num_samples_per_class = 5\n",
    "generated_images = []\n",
    "for i in range(10):  # 10 classes in Fashion MNIST\n",
    "    # Generate samples from the GMM\n",
    "    samples = gmm.sample(num_samples_per_class)[0]\n",
    "    # Decode the samples into images (assuming Gaussian distribution of pixel values)\n",
    "    samples = np.clip(samples, 0, 1)\n",
    "    images = samples.reshape(-1, 1, 28, 28)  # Reshape into images\n",
    "    generated_images.extend(images)\n",
    "\n",
    "# Step 6: Plot some of the generated images\n",
    "fig, axes = plt.subplots(10, num_samples_per_class, figsize=(num_samples_per_class, 10))\n",
    "for i in range(10):\n",
    "    for j in range(num_samples_per_class):\n",
    "        axes[i, j].imshow(generated_images[i * num_samples_per_class + j].transpose(1, 2, 0))\n",
    "        axes[i, j].axis('off')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:36:57.934548252Z",
     "start_time": "2024-04-12T20:27:21.389284789Z"
    }
   },
   "id": "947f26951edb5895",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b1dc43dc257b12e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
